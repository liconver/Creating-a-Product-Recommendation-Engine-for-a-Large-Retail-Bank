{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'E:\\Santander Recommendation\\train_ver2.csv')\n",
    "test = pd.read_csv(r'E:\\Santander Recommendation\\test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fecha_dato = pd.to_datetime(train.fecha_dato, format=\"%Y-%m-%d\")\n",
    "train.fecha_alta = pd.to_datetime(train.fecha_alta, format=\"%Y-%m-%d\")\n",
    "test.fecha_dato = pd.to_datetime(test.fecha_dato, format=\"%Y-%m-%d\")\n",
    "test.fecha_alta = pd.to_datetime(test.fecha_alta, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = train.fecha_dato.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wnewproducts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress =  0.058823529411764705\n",
      "progress =  0.11764705882352941\n",
      "progress =  0.17647058823529413\n",
      "progress =  0.23529411764705882\n",
      "progress =  0.29411764705882354\n",
      "progress =  0.35294117647058826\n",
      "progress =  0.4117647058823529\n",
      "progress =  0.47058823529411764\n",
      "progress =  0.5294117647058824\n",
      "progress =  0.5882352941176471\n",
      "progress =  0.6470588235294118\n",
      "progress =  0.7058823529411765\n",
      "progress =  0.7647058823529411\n",
      "progress =  0.8235294117647058\n",
      "progress =  0.8823529411764706\n",
      "progress =  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while i < len(months):\n",
    "    #select sequential months\n",
    "    new_month = train[train.fecha_dato == months[i]]\n",
    "    prev_month = train[train.fecha_dato == months[i-1]]\n",
    "    #select only customers present in both month\n",
    "    new_month = new_month.loc[new_month['ncodpers'].isin(prev_month.ncodpers)]\n",
    "    prev_month = prev_month.loc[prev_month['ncodpers'].isin(new_month.ncodpers)]\n",
    "    #sort by customer id so both months will be ordered the same\n",
    "    new_month.sort_values(by = 'ncodpers', inplace = True)\n",
    "    prev_month.sort_values(by = 'ncodpers', inplace = True)\n",
    "    #pick out product columns\n",
    "    product_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1',\n",
    "                'ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1',\n",
    "                'ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_dela_fin_ult1','ind_deme_fin_ult1',\n",
    "                'ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_nom_pens_ult1',\n",
    "                'ind_nomina_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1',\n",
    "                'ind_recibo_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1']\n",
    "    #new dataframe with just product\n",
    "    new_month_products = new_month[product_cols]\n",
    "    #add in the corresponding customer ids\n",
    "    new_month_products['ncodpers'] = new_month.ncodpers\n",
    "    #get rid of index\n",
    "    new_month_products.reset_index(drop=True,inplace=True)\n",
    "    #now repeat for the previous month but make ids zero so a subtraction works \n",
    "    prev_month_products = prev_month[product_cols]\n",
    "    prev_month_products['ncodpers'] = prev_month.ncodpers\n",
    "    prev_month_products.ncodpers = 0\n",
    "    prev_month_products.reset_index(drop=True,inplace=True)\n",
    "    #subtract to find the new products\n",
    "    new_products = new_month_products.subtract(prev_month_products)\n",
    "    #remove products that the customer dropped fill NA's\n",
    "    new_products[new_products < 0] = 0\n",
    "    new_products = new_products.fillna(0)\n",
    "    #merge the new products features with the month data\n",
    "    new_products = new_products.merge(new_month.iloc[:,0:24], on='ncodpers')\n",
    "    #add the interated months into training dataframe\n",
    "    train_wnewproducts = pd.concat([train_wnewproducts,new_products], axis = 0)\n",
    "    print(\"progress = \", float(i/len(months)))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wnewproducts = train_wnewproducts.loc[(train_wnewproducts.iloc[:,0:24] != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_month = train[train.fecha_dato == '2016-05-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_wnewproducts,test], axis = 0, ignore_index = True)\n",
    "train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtyrows = df[df.ind_empleado.isnull()].index\n",
    "\n",
    "df = df.drop(dirtyrows, axis = 0)\n",
    "\n",
    "df.canal_entrada = df.canal_entrada.fillna(\"Unknown\")\n",
    "\n",
    "df = df.drop(\"cod_prov\", 1)\n",
    "\n",
    "df.conyuemp = df.conyuemp.fillna(\"Unknown\")\n",
    "\n",
    "df.loc[df.indrel_1mes == '1', 'indrel_1mes'] = 'Primary'\n",
    "df.loc[df.indrel_1mes == '1.0', 'indrel_1mes'] = 'Primary'\n",
    "df.loc[df.indrel_1mes == 1, 'indrel_1mes'] = 'Primary'\n",
    "df.loc[df.indrel_1mes == 1.0, 'indrel_1mes'] = 'Primary'\n",
    "\n",
    "df.loc[df.indrel_1mes == '2', 'indrel_1mes'] = 'Co-owner'\n",
    "df.loc[df.indrel_1mes == '2.0', 'indrel_1mes'] = 'Co-owner'\n",
    "df.loc[df.indrel_1mes == 2, 'indrel_1mes'] = 'Co-owner'\n",
    "df.loc[df.indrel_1mes == 2.0, 'indrel_1mes'] = 'Co-owner'\n",
    "\n",
    "df.loc[df.indrel_1mes == '3', 'indrel_1mes'] = 'Former Primary'\n",
    "df.loc[df.indrel_1mes == '3.0', 'indrel_1mes'] = 'Former Primary'\n",
    "df.loc[df.indrel_1mes == 3, 'indrel_1mes'] = 'Former Primary'\n",
    "df.loc[df.indrel_1mes == 3.0, 'indrel_1mes'] = 'Former Primary'\n",
    "\n",
    "df.loc[df.indrel_1mes == '4', 'indrel_1mes'] = 'Former Co-owner'\n",
    "df.loc[df.indrel_1mes == '4.0', 'indrel_1mes'] = 'Former Co-owner'\n",
    "df.loc[df.indrel_1mes == 4, 'indrel_1mes'] = 'Former Co-owner'\n",
    "df.loc[df.indrel_1mes == 4.0, 'indrel_1mes'] = 'Former Co-owner'\n",
    "\n",
    "df.indrel_1mes  = df.indrel_1mes.fillna('Primary')\n",
    "\n",
    "df.nomprov = df.nomprov.fillna(\"MADRID\")\n",
    "\n",
    "df.loc[df.renta == '         NA',\"renta\"] = 0\n",
    "df.renta = df.renta.astype(float)\n",
    "df.loc[df.renta == 0, 'renta'] = df[df.renta > 0].groupby('nomprov').renta.transform('median')\n",
    "df.loc[df.renta.isnull(), \"renta\"] = df.groupby('nomprov').renta.transform('median')\n",
    "\n",
    "df.segmento = df[df.renta <= 98000].segmento.fillna(\"03 - UNIVERSITARIO\")\n",
    "df.segmento = df[df.renta <= 125500].segmento.fillna(\"02 - PARTICULARES\")\n",
    "df.segmento = df.segmento.fillna(\"01 - TOP\")\n",
    "\n",
    "df.sexo = df.sexo.fillna(\"V\")\n",
    "\n",
    "df.tiprel_1mes = df.tiprel_1mes.fillna('I')\n",
    "\n",
    "df.ind_nomina_ult1 = df.ind_nomina_ult1.fillna(0.0)\n",
    "df.ind_nom_pens_ult1 = df.ind_nom_pens_ult1.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.antiguedad == -999999, 'antiguedad'] = df[df.antiguedad.astype(float) >= 0].antiguedad.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ageGroup'] = (df.age.astype(float) // 10) - 1\n",
    "\n",
    "df['isSpanish'] = df.pais_residencia.map(lambda x: 1 if x == \"ES\" else 0)\n",
    "\n",
    "df['majorCity'] = df.nomprov.map(lambda x: 1 if x == \"MADRID\" or x == \"BARCELONA\" else 0)\n",
    "\n",
    "df['fecha_alta_year'] = pd.DatetimeIndex(df.fecha_alta).year - 1995\n",
    "df['fecha_dato_year'] = pd.DatetimeIndex(df.fecha_dato).year - 2015\n",
    "df['fecha_alta_month'] = pd.DatetimeIndex(df.fecha_alta).month - 1\n",
    "df['fecha_dato_month'] = pd.DatetimeIndex(df.fecha_dato).month - 1\n",
    "\n",
    "df.antiguedad = df.antiguedad.astype(int)\n",
    "df['antiguedad_years'] = df.antiguedad // 12\n",
    "\n",
    "df.loc[df.indrel == 99.0, \"indrel\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ult_fec_cli_1t.fillna(0)\n",
    "df['HAS_ult_fec_cli_1t'] = df.ult_fec_cli_1t.map(lambda x: 1 if type(x)==str else 0)\n",
    "\n",
    "df = df.drop('ult_fec_cli_1t', 1)\n",
    "\n",
    "df['rentaGroup'] = df.renta.astype(float) // 50000\n",
    "df.loc[df.renta >= 1000000, \"rentaGroup\"] = 20\n",
    "df.loc[df.renta >= 10000000, \"rentaGroup\"] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(train_wnewproducts)- len(dirtyrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final, test = df[:l], df[l:]\n",
    "train_final_training_cols = train_final\n",
    "train_final_training_cols = train_final_training_cols.drop(product_cols, axis=1)\n",
    "test = test.drop(product_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446022\n",
      "929615\n"
     ]
    }
   ],
   "source": [
    "print(len(train_final))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441020"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.ncodpers.isin(test.ncodpers).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_final_training_cols, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pais_residencia = df.pais_residencia.astype('category').cat.codes\n",
    "df.canal_entrada = df.canal_entrada.astype('category').cat.codes\n",
    "df.nomprov = df.nomprov.astype('category').cat.codes\n",
    "final_month.nomprov = final_month.indrel_1mes.astype('category').cat.codes\n",
    "df = pd.get_dummies(df, columns = ['ind_empleado','sexo','tiprel_1mes','indresi',\n",
    "                                   'indext','conyuemp','indfall','segmento','indrel_1mes'])\n",
    "\n",
    "df = df.drop(['fecha_dato', 'fecha_alta'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_training_cols, test = df[:l], df[l:]\n",
    "df=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "labels = train_final[product_cols]\n",
    "labels['ncodpers'] = train_final.ncodpers\n",
    "labels = labels.set_index(\"ncodpers\")\n",
    "stacked_labels = labels.stack()\n",
    "filtered_labels = stacked_labels.reset_index()\n",
    "filtered_labels.columns = [\"ncodpers\", \"product\", \"newly_added\"]\n",
    "filtered_labels = filtered_labels[filtered_labels[\"newly_added\"] == 1]\n",
    "multiclass_train = filtered_labels.merge(train_final_training_cols, on=\"ncodpers\", how=\"left\")\n",
    "train_final = multiclass_train.drop_duplicates(multiclass_train, keep='last')\n",
    "labels_final = train_final['product']\n",
    "train_final_ncodpers = train_final.ncodpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#insert some collaborative filtering features part 1\n",
    "train = pd.read_csv(r'E:\\Santander Recommendation\\train_ver2.csv')\n",
    "lastmonth = train.loc[train['fecha_dato']=='2016-05-28']\n",
    "train=[]\n",
    "lastmonthlabels = lastmonth[product_cols]\n",
    "lastmonthlabels['ncodpers'] = lastmonth.ncodpers #check if another last month\n",
    "lastmonthlabels = lastmonthlabels.set_index('ncodpers')\n",
    "stacked_lastmonthlabels = lastmonthlabels.stack()\n",
    "filtered_lastmonthlabels = stacked_lastmonthlabels.reset_index()\n",
    "filtered_lastmonthlabels.columns = [\"ncodpers\", \"product\", \"is_owned\"]\n",
    "lastmonthlabels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1917\n",
      "0.19168434530058975\n"
     ]
    }
   ],
   "source": [
    "#CF part 2\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "reader = Reader(line_format='user item rating', rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(filtered_lastmonthlabels, reader=reader)\n",
    "trainset, testset = train_test_split(data, test_size=.05)\n",
    "algo = SVD(n_factors=50,verbose=True)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "print(accuracy.rmse(predictions))\n",
    "latentfeatures = pd.DataFrame(algo.pu)\n",
    "latentfeatures['ncodpers'] = lastmonth.ncodpers.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF part 3: add the features\n",
    "test = pd.merge(test, latentfeatures,how='inner',on='ncodpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.merge(train_final, latentfeatures, how='inner', on='ncodpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_final = train_final['product']\n",
    "train_final_ncodpers = train_final.ncodpers\n",
    "train_final = train_final.drop(['ncodpers','newly_added','product'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_month = pd.merge(final_month,latentfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to go through and describe each step\n",
    "dirtyrows = final_month[final_month.ind_empleado.isnull()].index\n",
    "final_month = final_month.drop(dirtyrows, axis = 0)\n",
    "final_month.canal_entrada = final_month.canal_entrada.fillna(\"Unknown\")\n",
    "final_month = final_month.drop(\"cod_prov\", 1)\n",
    "final_month.conyuemp = final_month.conyuemp.fillna(\"Unknown\")\n",
    "final_month.loc[final_month.indrel_1mes == '1', 'indrel_1mes'] = 'Primary'\n",
    "final_month.loc[final_month.indrel_1mes == '1.0', 'indrel_1mes'] = 'Primary'\n",
    "final_month.loc[final_month.indrel_1mes == 1, 'indrel_1mes'] = 'Primary'\n",
    "final_month.loc[final_month.indrel_1mes == 1.0, 'indrel_1mes'] = 'Primary'\n",
    "final_month.loc[final_month.indrel_1mes == '2', 'indrel_1mes'] = 'Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == '2.0', 'indrel_1mes'] = 'Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == 2, 'indrel_1mes'] = 'Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == 2.0, 'indrel_1mes'] = 'Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == '3', 'indrel_1mes'] = 'Former Primary'\n",
    "final_month.loc[final_month.indrel_1mes == '3.0', 'indrel_1mes'] = 'Former Primary'\n",
    "final_month.loc[final_month.indrel_1mes == 3, 'indrel_1mes'] = 'Former Primary'\n",
    "final_month.loc[final_month.indrel_1mes == 3.0, 'indrel_1mes'] = 'Former Primary'\n",
    "final_month.loc[final_month.indrel_1mes == '4', 'indrel_1mes'] = 'Former Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == '4.0', 'indrel_1mes'] = 'Former Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == 4, 'indrel_1mes'] = 'Former Co-owner'\n",
    "final_month.loc[final_month.indrel_1mes == 4.0, 'indrel_1mes'] = 'Former Co-owner'\n",
    "final_month.indrel_1mes = final_month.indrel_1mes.fillna('Primary')\n",
    "final_month.nomprov = final_month.nomprov.fillna(\"MADRID\")\n",
    "final_month.renta = final_month.renta.astype(float)\n",
    "final_month.loc[final_month.renta.isnull(), \"renta\"] = final_month.groupby('nomprov').renta.transform('median')\n",
    "final_month.segmento = final_month[final_month.renta <= 98000].segmento.fillna(\"03 - UNIVERSITARIO\")\n",
    "final_month.segmento = final_month[final_month.renta <= 125500].segmento.fillna(\"02 - PARTICULARES\")\n",
    "final_month.segmento = final_month.segmento.fillna(\"01 - TOP\")\n",
    "final_month.sexo = final_month.sexo.fillna(\"V\")\n",
    "final_month.tiprel_1mes = final_month.tiprel_1mes.fillna('I')\n",
    "final_month.ind_nomina_ult1 = final_month.ind_nomina_ult1.fillna(0.0)\n",
    "final_month.ind_nom_pens_ult1 = final_month.ind_nom_pens_ult1.fillna(0.0)\n",
    "final_month.loc[final_month.antiguedad == -999999, 'antiguedad'] = final_month[final_month.antiguedad >= 0].antiguedad.median()\n",
    "final_month.age = final_month.age.astype(int)\n",
    "final_month.loc[final_month.age < 20,\"age\"] = 19\n",
    "final_month.loc[final_month.age > 90,\"age\"] = 91\n",
    "final_month['ageGroup'] = (final_month.age // 10) - 1\n",
    "final_month['isSpanish'] = final_month.pais_residencia.map(lambda x: 1 if x == \"ES\" else 0)\n",
    "final_month['majorCity'] = final_month.nomprov.map(lambda x: 1 if x == \"MADRID\" or x == \"BARCELONA\" else 0)\n",
    "final_month['fecha_alta_year'] = pd.DatetimeIndex(final_month.fecha_alta).year - 1995\n",
    "final_month['fecha_dato_year'] = pd.DatetimeIndex(final_month.fecha_dato).year - 2015\n",
    "final_month['fecha_alta_month'] = pd.DatetimeIndex(final_month.fecha_alta).month - 1\n",
    "final_month['fecha_dato_month'] = pd.DatetimeIndex(final_month.fecha_dato).month - 1\n",
    "final_month.antiguedad = final_month.antiguedad.astype(int)\n",
    "final_month['antiguedad_years'] = final_month.antiguedad // 12\n",
    "final_month.loc[final_month.indrel == 99.0, \"indrel\"] = 0.0\n",
    "final_month.ult_fec_cli_1t.fillna(0)\n",
    "final_month['HAS_ult_fec_cli_1t'] = final_month.ult_fec_cli_1t.map(lambda x: 1 if type(x) == str else 0)\n",
    "final_month = final_month.drop('ult_fec_cli_1t', 1)\n",
    "final_month['rentaGroup'] = final_month.renta.astype(float) // 50000\n",
    "final_month.loc[final_month.renta >= 1000000, \"rentaGroup\"] = 20\n",
    "final_month.loc[final_month.renta >= 10000000, \"rentaGroup\"] = 21\n",
    "final_month_training_cols = final_month\n",
    "final_month_training_cols = final_month_training_cols.drop(product_cols, axis=1)\n",
    "final_month.pais_residencia = final_month.pais_residencia.astype('category').cat.codes\n",
    "final_month.canal_entrada = final_month.canal_entrada.astype('category').cat.codes\n",
    "final_month.nomprov = final_month.nomprov.astype('category').cat.codes\n",
    "final_month.nomprov = final_month.indrel_1mes.astype('category').cat.codes\n",
    "final_month = pd.get_dummies(final_month, columns = ['ind_empleado','sexo','tiprel_1mes','indresi',\n",
    "                                   'indext','conyuemp','indfall','segmento','indrel_1mes'])\n",
    "final_month = final_month.drop(['fecha_dato', 'fecha_alta'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "labels_final_month = final_month[product_cols]\n",
    "labels_final_month['ncodpers'] = final_month.ncodpers\n",
    "labels_final_month = labels_final_month.set_index(\"ncodpers\")\n",
    "stacked_labels_final_month = labels_final_month.stack()\n",
    "filtered_labels_final_month = stacked_labels_final_month.reset_index()\n",
    "filtered_labels_final_month.columns = [\"ncodpers\", \"product\", \"newly_added\"]\n",
    "filtered_labels_final_month = filtered_labels_final_month[filtered_labels_final_month[\"newly_added\"] == 1]\n",
    "multiclass_final_month = filtered_labels_final_month.merge(final_month_training_cols, on=\"ncodpers\", how=\"left\")\n",
    "final_month = multiclass_final_month.drop_duplicates(multiclass_final_month, keep='last')\n",
    "labels_final_month_final = final_month['product']\n",
    "final_month_ncodpers = final_month.ncodpers\n",
    "final_month = final_month.drop(['ncodpers','newly_added','product'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013148\n",
      "1013148\n",
      "1240538\n",
      "1240538\n"
     ]
    }
   ],
   "source": [
    "print(len(train_final))\n",
    "print(len(labels_final))\n",
    "print(len(final_month))\n",
    "print(len(labels_final_month_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind_recibo_ult1      223500\n",
       "ind_nom_pens_ult1    151815\n",
       "ind_nomina_ult1      135539\n",
       "ind_cco_fin_ult1     121625\n",
       "ind_tjcr_fin_ult1    115884\n",
       "ind_cno_fin_ult1      93696\n",
       "ind_ecue_fin_ult1     58871\n",
       "ind_dela_fin_ult1     26004\n",
       "ind_reca_fin_ult1     24385\n",
       "ind_ctma_fin_ult1     15534\n",
       "ind_valo_fin_ult1     12290\n",
       "ind_ctop_fin_ult1      8839\n",
       "ind_fond_fin_ult1      8748\n",
       "ind_ctpp_fin_ult1      6438\n",
       "ind_deco_fin_ult1      5935\n",
       "ind_plan_fin_ult1      1791\n",
       "ind_deme_fin_ult1       600\n",
       "ind_ctju_fin_ult1       505\n",
       "ind_pres_fin_ult1       406\n",
       "ind_cder_fin_ult1       344\n",
       "ind_hip_fin_ult1        199\n",
       "ind_viv_fin_ult1        191\n",
       "ind_aval_fin_ult1         6\n",
       "ind_ahor_fin_ult1         3\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_final = labels_final.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('ncodpers', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wnewproducts = []\n",
    "data = []\n",
    "trainset = []\n",
    "testset = []\n",
    "algo = []\n",
    "predictions = []\n",
    "latentfeatures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_final, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810518, 95)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (810518, 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-aea25086b017>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlsvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m--> 227\u001b[1;33m                          dtype=np.float64, order=\"C\")\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m                         dtype=None)\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (810518, 24)"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "model = SelectFromModel(lsvc, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_train = model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=50,oob_score=True,max_features=.33,random_state=1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.33, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_target_forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = multi_target_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledclassprobs = pd.DataFrame(y_pred_prob[0][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,24):\n",
    "    s = pd.Series(y_pred_prob[i][:,1])\n",
    "    compiledclassprobs = pd.concat([compiledclassprobs,s],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.841843796345737"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,compiledclassprobs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_final_month_final_cat = labels_final_month_final.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_products = pd.DataFrame()\n",
    "used_products['product'] = labels_final_month_final_cat\n",
    "used_products['ncodpers'] = final_month_ncodpers\n",
    "used_products = used_products.drop_duplicates(keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to store each product a customer already has\n",
    "used_recommendation_products = {}\n",
    "product_cols = np.array(product_cols)\n",
    "#iterate through used_products and add each one to used_recommendation_products\n",
    "for idx,row_val in used_products.iterrows():\n",
    "    used_recommendation_products.setdefault(row_val['ncodpers'],[]).append(product_cols[row_val['product']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_cco_fin_ult1',\n",
       " 'ind_ctpp_fin_ult1',\n",
       " 'ind_tjcr_fin_ult1',\n",
       " 'ind_valo_fin_ult1']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_recommendation_products[15889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltest = normalize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpredsraw = multi_target_forest.predict_proba(modeltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledclassprobs = pd.DataFrame(modelpredsraw[0][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,24):\n",
    "    s = pd.Series(modelpredsraw[i][:,1])\n",
    "    compiledclassprobs = pd.concat([compiledclassprobs,s],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpreds = compiledclassprobs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argsort(modelpreds, axis=1)\n",
    "pred = np.fliplr(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 20, 13,  2, 22, 10, 15, 12,  6, 16, 23,  7,  1,  3,  4,  5, 11,\n",
       "        8,  9, 14, 17, 18, 19,  0], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = np.array(pd.read_csv(r'E:\\Santander Recommendation\\test_ver2.csv',usecols=['ncodpers'])['ncodpers'])\n",
    "product_cols = np.array(product_cols)\n",
    "final_preds = []\n",
    "#iteratively create the final rank ordered recommendations for each user, exluding ones the customer already has\n",
    "for idx,predicted in enumerate(pred):\n",
    "    ids = test_ids[idx]\n",
    "    top_product = product_cols[predicted]\n",
    "    used_products = used_recommendation_products.get(ids,[])\n",
    "    new_top_product = []\n",
    "    for product in top_product:\n",
    "        if product not in used_products:\n",
    "            new_top_product.append(product)\n",
    "        if len(new_top_product) == 7:\n",
    "            break\n",
    "    final_preds.append(' '.join(new_top_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ncodpers':test_ids,'added_products':final_preds})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 2)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=[]\n",
    "final_preds=[]\n",
    "compiledclassprobs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
